---
version: '2'
services:
  backend:
    build:
      context: ./customer_support_usecase_backend
    container_name: customer_support_usecase_backend
    image: customer_support_usecase_backend
    volumes: [vector_db:/vector_db]
    ports: 8000:8000
    environment:
      - MONGO_URL=mongodb://database:27017/
      - INFERENCE_URL=http://tgi:8080
      - VECTOR_DB_LOCATION=/vector_db/faiss_database
      - DATABASE_TYPE=test
      - CHUNK_SIZE=250
      - CHUNK_OVERLAP=10
      - CHUNK_COUNT=2
  frontend:
    build:
      context: ./customer_support_usecase_frontend
    container_name: customer_support_usecase_frontend
    image: customer_support_usecase_frontend
    ports: 3000:5173
    environment:
      - VITE_BACKEND_URL=http://insert_backend_url:8000
      - VITE_SESSION_ID=656f20b414828b118cef987b
      - VITE_SSE_URL=http://tgi:8080
      - VITE_MAX_NEW_TOKENS=500
  tgi:
    container_name: tgi-llama-2-7b-chat
    image: ghcr.io/huggingface/text-generation-inference:1.3
    command: [--model-id, meta-llama/Llama-2-7b-chat-hf]
    volumes: [/home/akarx/text2sql-codebase/chatbot/models:/app/models]
  database:
    image: mongo
    container_name: mongodb
    volumes: [mongo-volume:/data/db]
